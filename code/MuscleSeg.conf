# Configuration for ImageNet  
# Acknowledgement:
#  Ref: http://www.cs.toronto.edu/~fritz/absps/imagenet.pdf
#  The scheduling parameters is adapted from Caffe(http://caffe.berkeleyvision.org/)

data = train
iter = imgbin
  image_list = "/media/labuser/Data2/Manish/cxxnet-master/example/MNIST/data/cxxnet_lst.txt"
  image_bin  = "/media/labuser/Data2/Manish/cxxnet-master/example/MNIST/data/cxxnet_muscle.bin"
  image_mean = "models/muscle_net_mean.bin"
#divideby = 256
shuffle = 1
iter = threadbuffer
iter = end

eval = test
iter = imgbin
  image_list = "/media/labuser/Data2/Manish/cxxnet-master/example/MNIST/data/cxxnet_lst.txt"
  image_bin  = "/media/labuser/Data2/Manish/cxxnet-master/example/MNIST/data/cxxnet_muscle.bin"
  image_mean = "models/muscle_net_mean.bin"
#divideby = 256
shuffle = 1
# no random crop and mirror in test
iter = end

netconfig=start
layer[0->1] = conv
  kernel_size = 4
  stride = 1
  nchannel = 20
layer[1->2] = relu
layer[2->3] = max_pooling
  kernel_size = 2
  stride = 2
###############
layer[3->4] = conv
  kernel_size = 4
  stride = 1
  nchannel = 20
layer[4->5] = relu
layer[5->6] = max_pooling
  kernel_size = 2
  stride = 2
###############
layer[6->7] = conv
  kernel_size = 2
  stride = 1
  nchannel = 20
layer[7->8] = relu
layer[8->9] = max_pooling
  kernel_size = 2
  stride = 2
#############
layer[9->10] = flatten
layer[10->11] = fullc
  nhidden = 500
  init_sigma = 0.005
  init_bias = 1.0
layer[11->12] = relu
layer[12->13] = fullc
  nhidden = 250
  init_sigma = 0.005
  init_bias = 1.0
layer[13->14] = fullc
  nhidden = 2
layer[14->14] = softmax
netconfig=end

# evaluation metric
metric[label] = error


max_round = 5
num_round = 5

# input shape not including batch
input_shape = 3,33,33

batch_size = 100

# global parameters in any sectiion outside netconfig, and iter
dev = cpu:0-5
momentum = 0.9
wmat:lr  = 0.01
wmat:wd  = 0.0005

bias:wd  = 0.000
bias:lr  = 0.02

# all the learning rate schedule starts with lr
lr:schedule = expdecay
lr:gamma = 0.1
lr:step = 100000

save_model=1
model_dir=models

# random config
random_type = xavier


# new line
